## 과대적합(Overfitting)
  - 일반화 (Generalization)
    - 모델이 새로운 데이터셋(테스트 데이터)에 대하여 정확히 예측하면 이것을 (훈련데이터에서 테스트데이터로) 일반화 되었다고 한다
    - 모델이 훈련 데이터로 평가한 결과와 테스트 데이터로 평가한 결과의 차이가 거의 없고 좋은 평가지표를 보여준다

  - 과대적합(Overfitting)
    - 모델이 훈련 데이터에 대한 예측성능은 너무 좋지만 일반성이 떨어져 새로운 데이터(테스트 데이터)에 대한 성능이 좋지 않음
    - 이는 모델이 훈련 데이터세트의 특징에만 너무 맞춰서 학습되어서 일반화 되지 않아 새로운 데이터에 대한 예측 성능이 떨어져서 발생한다

  - 과소적합(Underfitting)
    - 모델이 훈련 데이터와 테스트 데이터셋 모두에서 성능이 좋지 않은 경우
    - 모델이 너무 간단하여 훈련데이터에 대해 충분히 학습하지 못해 데이터셋의 패턴을 다 찾아내지 못할 때 발생한다

![image](https://user-images.githubusercontent.com/76146752/112487021-c21ecb00-8dbf-11eb-8a70-f1580cd1154e.png)

## Overfitting(과대적합)의 원인
  - 모델이 너무 복잡한 경우
    - Overfitting을 줄이기 위한 규제 하이퍼파라미터 설정
    - Feature 개수 줄이기

  - 데이터의 문제
    - 데이터 전처리를 통해 질 좋은 데이터를 만든다
    - 데이터를 더 수집한다 (but 비용과 시간의 문제로 현실적으로 어려운 경우가 많음)

- 
  ``` python
      from sklearn.datasets import load_breast_cancer
      from sklearn.model_selection import train_test_split
      
      cancer = load_breast_cancer()
      X,y = cancer['data'], cancer['target']
      
      X_train,X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=1)
      
      from sklearn.tree import DecisionTreeClassifier
      from sklearn.metrics import accuracy_score
      
      tree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)
      tree.fit(X_train,y_train)
      
      pred_train = tree.predict(X_train)
      pred_test = tree.predict(X_test)
      
      # 정확도
      print('train 정확도:',accuracy_score(y_train,pred_train))
      print('test 정확도:',accuracy_score(y_test,pred_test))
      
      # 의사결정 트리의 경우 max_depth를 설정하지않으면 확률이 1일때까지 계속 하기 때문에 과적합이 일어 나기 쉬우므로 하이퍼파라미터이를 설정해 주는 것이 좋음
  ```
  
- 
  ``` python
      from sklearn.tree import export_graphviz
      from graphviz import Source
      
      graph = Source(export_graphviz(tree, out_file= None, feature_names = cancer['feature_names'], class_names=cancer['target_names'], rounded=True, filled = True))
      
   ```

### Decision Tree 복잡도 제어(규제)
  - Decision Tree 모델을 복잡하게 하는 것은 노드가 너무 많이 만들어 지는것임
    - 노드가 많이 만들어질수록 훈련데이터셋에 과대 적합된다
  - 따라서 적절한 시점에 트리 생성을 중단해야함
  - 규제 하이퍼파라미터
    - max_depth : 트리의 최대 깊이를 제한
    - max_leaf_nodes : Leaf node의 최대 개수를 제한
    - min_sample_leaf: leaf node가 되기 위한 sample 수 지정
  ### GridSearch (그리드 서치)
  
  - 적당한 max_depth 찾기
  - 
    ```  python
         depth_list = range(1,11) # max_depth 에 지정할 후보 (1~10)
         # 각각의 max_depth 에 따른 train과 test 데이터의 정확도를 저장할 리스트
         train_acc_list = []
         test_acc_list = []
         
         # max_depth에 하나 씩 넣어 정확도 비교
         for depth in depth_list:
          tree = DecisionTreeClassifier(max_depth=depth, random_state=1)
          tree.fit(X_train, y_train)
          
          pred_train = tree.predict(X_train)
          pred_test = tree.predict(X_test)
          
          train_acc_list.append(accuracy_score(y_train,pred_train))
          test_acc_list.append(accuracy_score(y_test, pred_test))
          
         import pandas as pd
         
         result = pd.DataFrame(dict(max_depth = depth_list, train= train_acc_list, test = test_acc_list))
         
         import matplotlib.pyplot as plt
         
         plt.figure(figsize=(7,7))
         plt.plot(depth_list, train_acc_list, label = 'Train acc')
         plt.plot(depth_list, test_acc_list, label= 'Test acc')
         plt.xlabel('max_depth')
         plt.legend()
         plt.show()
     ```
     ![image](https://user-images.githubusercontent.com/76146752/112501691-cc939180-8dcc-11eb-81b2-2249189a3671.png)
 
  #### Grid Search 를 이용한 하이퍼파라미터 튜닝
   - 하이퍼파라미터 (Hyper Parameter)
    - 머신러닝 모델을 생성할 떄 사용자가 직접 설정하는 값
    - 머신러닝 모델에 따라 다르기는 하지만 많은 하이퍼파라미트를 변경할 수 있다

   - 하이퍼 파라미터 튜닝
      - 하이퍼 파라미터의 설정에 따라 모델의 성능이 달라지므로 하이퍼파라미터를 조정하면서 성능을 높임

 #### 최적의 하이퍼파라미터 찾기
  
  1. 만족할 성능을 가진 하이퍼파라미터들의 값의 조합을 찾을때까지 일일이 수동으로 조정
  2. GridSearch 사용
      - GridSearchCV()
          - 시도해볼 하이퍼파라미터들을 지정하면 모든 조합에 대해 교차검증 후 제일 좋은 성능을 내는 하이퍼파라미터 조합을 찾아줌
          - 적은 수의 조합의 경우는 괜찮지만 시도할 하이퍼파라미터와 값들이 많아지면 너무 많은 시간이 걸린다
  3. Random Search 사용
      - RandomizedSearchCV()
          - GridSearch와 동일한 방식으로 사용한다
          - but GridSearch와 다르게 모든 조합을 다 시도하지는 않고 각 반복마다 임의의 값만 대입해 지정한 횟수만큼만 평가

  #### GridSearchCV 매개변수 및 결과 조회
    
   - 주요 매개변수
        - estimator: 모델객체 지정
        - params : 하이퍼파라미터 목록을 dictionary로 전달 ('파라미터명': [파라미터값 list] 형식
        - scoring :평가지표
        - cv :교차 검증시 fold개수
        - n_jobs : 사용할 CPU코어 개수 (None: 1(기본값), -1: 모든 코어 다 사용)

   - 메소드
        - fit(X,y) : 학습
        - predict(X) : 제일 좋은 성능을 낸 모델로 predict()
        - predict_proba(X): 제일 좋은 성능을 낸 모델로 predict_proba() 호출
   - 결과 조회 변수
        - cv_results_ : 파라미터 조합별 결과 조회
        - best_params_ : 가장 좋은 성능을 낸 parameter 조합 조회
        - best_estimator_ : 가장 좋은 성능을 낸 모델 반환

   - 
     ``` python
         
         from sklearn.datasets import load_breast_cancer
         from sklearn.model_selection import train_test_split
         
         X,y = load_breas_cancer(return_X_y = True)
         
         X_train, X_test, y_train, y_test = train_test_split(X,y, stratify = y, random_state=1)
         
         from sklearn.tree import DecisionTreeClassifier
         from sklearn.model_selection import GridSearchCV
         
         tree = DecisionTreeClassifier()
         # 하이퍼파라미터 후보들을 딕셔너리로 지정 파라미터이름: [후보]
         # 지정하지 않은 것들은 default값을 사용
         
         param_grid = {
            'max_depth': range(1,11),
            'max_leaf_nodes': [3,5,7,9],
            'random_state': [1]
         }
         
         grid_search = GridSearchCV(tree,
                                    param_grid = param_grid,
                                    scoring = ['accuracy','recall','precision'],
                                    refit = 'accuracy', # 평가지표가 여러 개일때 어떤 지표를 기준으로 best_estimator를 정할지 기준을 정함
                                    cv = 5, # 교차검증시 folder의 개수
                                    n_jobs = -1)
                                    
         # 학습(train)
         grid_search.fit(X_train,y_train)
         
         from sklearn.metrics import accuracy_score
         pred_train = grid_search.predict(X_train)
         accuracy_score(y_train, pred_train)
         
         # 하이퍼파라미터 조합별 결과
         df = pd.DataFrame(grid_search.cv_results)
         
         # 최적의 하이퍼파라미터
         best_param = grid_search.best_params_
         
         best_estimator = grid_search.best_estimator_
         
         pr = best_estimator.predict(X_train)
         accuracy_score(y_train, pr)
         
#### RandomizedSearchCV
  - 주요 매개변수
      - estimator: 모델객체 지정
      - param_distributions: 하이퍼파라미터 목록을 dictionary로 전달
      - n_iter: 파라미터 검색횟수
      - scoring :평가지표
      - cv :교차검증시 fold 개수
      - n_jobs : 사용할 CPU 코어 개수
  
  - 메소드
      - fit(X,y) : 학습
      - predict(X) : 제일 좋은 성능을 낸 모델로 predict()
      - predict_proba(X): 제일 좋은 성능을 낸 모델로 predict_proba() 호출
  - 결과 조회 변수
      - cv_results_ : 파라미터 조합별 결과 조회
      - best_params_ :가장 좋은 성능을 낸 parameter 조합 조회
      - best_estimator_ : 가장 좋은 성능을 낸 모델 반환

   - 
     ``` python
         
         from sklearn.model_selection import RandomizedSearchCV
         
         tree = DecisionTreeClassifier()
         param_grid = {
              'max_depth':range(1,21),
              'max_leaf_nodes':range(2,11),
              'criterion' : ['gini','entropy'],
              'random_state' : [1]
         }
         n_iter = 50 # 확인할 수 있는 조합의 개수 모든 조합을 다 처리하는 것이 아니라 50개의 랜덤한 조합을 처리
         randomized_search = RandomizedSearchCV(tree,
                                                param_distributions = param_grid,
                                                n_iter = n_iter,
                                                scoring = 'accuracy',
                                                cv = 3,
                                                n_jobs=-1)
                                                
         randomize_search.fit(X_train,y_train)
         
         df = pd.DataFrame(randomized_search.cv_results_)
         
         df.sort_values('rank_test_score')
         
         randomized_search.best_params_ # 성능이 가장 좋은 하이퍼파라미터 반환
         randomized_search.best_estimator_ # 성능이 가장 좋은 모델 반환
      ```
  ### 파이프라인 (Pipeline)
   - 개요
      - 여러 단계의 머신러닝 프로세스 (전처리의 각단계, 모델생성, 학습) 처리 과정을 설정하여 한 번에 처리되도록 한다
   - 파이프라인은 여러개의 변환기와 마지막에 변환기 또는 추정기를 넣을 수 있다 (추정기 - Estimator는 마지막에만 올 수 있음)
   - 전처리 작업 파이프라인
      - 변환기들로만 구성
   - 전체 프로세스 파이프 라인
      - 마지막에 추정기를 넣음
  #### pipeline 생성
  - 이름, 변환기를 리스트로 묶어서 전달
  - 마지막에는 추정기 올수 있음

  #### pipeline 을 이용한 학습
   - pipeline.fit()
      - 각 순서대로 각 변환기의 fit_transform()을 실행하고 그 결과가 다음단계로 전달
      - 마지막 단계에서는 fit()만 호출
   
   - pipeline.transform() 
      - fit() 과 동일하지만 마지막 단계에서도 fit_transform() 실행
      - 보통 전처리 작업 파이프라인(모든 단계가 변환기) 일때 사용됨

   - 
     ``` python
         from sklearn.svm import SVC
         from sklearn.preprocessing import StandardScaler
         from sklearn.pipeline import Pipeline
         
         order = [
            ('scaler', StandardScaler()),
            ('svc',SVC())
         ]
         pipeline = Pipeline(order, verbose=True)
         print(pipeline.steps)
         
         # 학습
         pipeline.fit(X_train,y_train)
         
         # 예측
         pred_train = pipeline.predict(X_train)
         pred_test = pipeline.predict(X_test)
         
         accuracy_score(y_train, pred_train)
         accuracy_score(y_test, pred_test)
     ```

 #### GridSearch에서 Pipeline 사용
  - 하이퍼파라미터 지정시 파이프라인 ```프로세스이름__하이퍼파라미터``` 형식으로 지정
  - 
    ``` python
        param_grid = {
            'svc__C' = [0.001,0.01,0.1,0,1,10,100],
            'svc__gamma = [0.001,0.01,0,1,10,100]
        }
        grid_search = GridSearchCV(pipeline,
                                   param_grid = param_grid,
                                   scoring = 'accuracy',
                                   cv = 3,
                                   n_jobs=-1)
        grid_search.fit(X_train,y_train)
        
        pd.DataFrame(gird_search.cv_results_)
        
        grid_search.best_params_
        
        pred_train = grid_search.predict(X_train)
        pred_test = grid_search.predict(X_test)
        
        accuracy_score(y_train, pred_train)
        accuracy_score(y_test, pred_test)
    ```
 ### make_pipeline() 한수를 이용한 파이프라인 생성 편리하게 하기
  - 
    ``` python
        from sklearn.pipeline import make_pipelline
        
        pipeline2 = make_pipeline(StandardScaler(),SVC())
        pipeline2.steps # 이름이 함수 이름으로 자동으로 생성됨
    ```
