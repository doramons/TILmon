## íšŒê·€(Regression)
  ì§€ë„í•™ìŠµ(Supervised Learning)ìœ¼ë¡œ ì˜ˆì¸¡í•  Targetì´ ì—°ì†í˜•(continuous) ë°ì´í„°(float)ì¸ ê²½ìš°
  
### íšŒê·€ì˜ ì£¼ìš” í‰ê°€ ì§€í‘œ
  ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ê°’ ê°„ì˜ ì°¨ì´(ì˜¤ì°¨)ë¥¼ êµ¬í•œë‹¤
  
  - MSE (Mean Squared Error)
  
  - RMSE (Root Mean Squared Error)
  
  - R^2 (R square, ê²°ì •ê³„ìˆ˜)
    - í‰ê· ìœ¼ë¡œ ì˜ˆì¸¡í–ˆì„ ë•Œ ì˜¤ì°¨(ì´ ì˜¤ì°¨) ë³´ë‹¤ ëª¨ë¸ì„ ì‚¬ìš©í–ˆì„ ë•Œ ì–¼ë§ˆë§Œí¼ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ”ì§€ë¥¼ ë¹„ìœ¨ë¡œ ë‚˜íƒ€ë‚¸ ê°’
    - 1ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸
    - r2_score()
    - 'r2'
        - ğ‘¦ğ‘–  : ië²ˆì§¸ ì‹¤ì œ ê°’,

        - ğ‘¦ğ‘–^  : i ë²ˆì§¸ ì˜ˆì¸¡ ê°’,

        - ğ‘¦Â¯  : yì˜ í‰ê· 

 ### Guide
  - ê²°ì •ê³„ìˆ˜ . ë°”ì´ì˜¤ì—ì„  90%, ê³µí•™ì—ì„œëŠ” 70%, ì‚¬íšŒê³¼í•™ì—ì„  13% ì •ë„ê°€ ê¸°ì¤€ì´ ëœë‹¤ê³  í•œë‹¤
  - 
    ``` python
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        from sklearn.datasets import make_regression
        from sklearn.model_selection impmort cross_val_score
        from sklearn.linear_model import LinearRegression
        
        X,y = make_regression(n_samples = 100,
                              n_features = 1,
                              n_informative = 1,
                              noise = 50,
                              coef = False,
                              random_state = 1)
                              
        lr = LinearRegression()
        lr.fit(X,y)
        
        pred = lr.predict(X)
        
        from sklearn.metrics import mean_squared_error, r2score, mean_absolute_error
        
        mse = mean_square_error(y,pred)
        r2 = r2_score(y,pred)
        mae = mean_absolute_error(y,pred)
        
        score = cross_val_score(lr, X,y, cv=5)
        np.mean(score)
        
        cross_val_score(lr,X,y,scoring = 'neg_mean_squared_error',cv = 5)*-1
        # ì˜¤ì°¨ì ìˆ˜ì˜ ê²½ìš° ë‚®ì„ìˆ˜ë¡ ì„±ëŠ¥ì´ ì¢‹ì€ê²ƒì¸ë° ì–‘ìˆ˜ë¡œ ê³„ì‚°í•˜ê²Œ ë˜ë©´ ì •ë ¬ì´ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ë˜ê¸° ë•Œë¬¸ì— ìŒìˆ˜ë¡œ ë‚˜ì˜¤ê²Œ í•œë‹¤
        
        lr.coef_, lr.intercept_ # ê°€ì¤‘ì¹˜ì™€ ì ˆí¸ê°’
        
        plt.scatter(X,y,label='truth')
        y_hat = X*lr.coef + lr.intercept_
        plt.plot(X,y_hat, color = 'red',label='prediction')
        plt.legend()
    ```
    
 #### ê¸°ì¡´ ë¶„ë¥˜ ëª¨ë¸ê³¼ íšŒê·€ ëª¨ë¸
 
 - 
  ``` python'
      from sklearn.model_selection import train_test_split
      from sklearn.neighbors import KNeighborsRegressor
      from sklearn.tree import DecisionTreeRegressor
      from sklearn.ensemble import RandomForestRegressor, VotingRegressor
      from sklearn.linear_model import LinearRegression
      
      X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state=12) # stratifyëŠ” ë¶„ë¥˜ì—ì„œë§Œ ì§€ì •í•´ì£¼ê³  íšŒê·€ì—ì„œëŠ” X
      
      knn_reg = KNeighborsRegressor(n_neighbors=3)
      tree_reg = DecisionTreeRegressor(max_depth=5)
      rf_reg = RandomForestRegressor(n_estimators = 300, max_depth = 2)
      lr_reg = LinearRegression()
      
      estimators = [('knn',knn_reg},('tree',tree_reg),('random forest',rf_reg)]
      
      def print_metrics(y,y_pred, title=None):
        mse = mean_squared_error(y,y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y,y_pred)
        if title:
          print(title)
        print(f'MSE:{mse}, RMSE:{rmse}, R2:{r2}')
        
       r2_list = []
       mse_list = []
       
       for name, model in estimators:
          model.fit(X_train,y_train)
          pred_train = model.predict(X_train)
          pred_test = model.predict(X_test)
          
          print_metrics(y_train,pred_train, name+' -Train')
          print_metrics(y_test,pred_test, name+' -Test')
          print('---------------------------------------')
          
       #VotingRegressor

       vote_reg = VotingRegressor(estimators)
       vote_reg.fit(X_train,y_train)

       pred_train = vote_reg.predict(X_train)
       pred_test = vote_reg.predict(X_test)

       print_metrics(y_train,pred_train)
       print_metrics(y_test, pred_test)
         
       tree_reg = DecisionTreeRegressor(max_depth=3)
       
       tree_reg.fit(X_train,y_train)
       
       from sklearn.tree import export_graphviz
       from graphviz import Source
       
       graph = Source(export_graphviz(tree_reg,
                                      out_file = None,
                                      rounded = True,
                                      filled = True))
   ```
      








