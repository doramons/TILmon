![image](https://user-images.githubusercontent.com/76146752/111751820-46f97880-88d8-11eb-95bb-72b37333daf0.png)

### 데이터셋
  - **Train 데이터셋(훈련/학습 데이터셋)**
    - 모델을 학습시킬 때 사용할 데이터셋
  - **Validation 데이터셋 (검증 데이터셋)**
    - Train set으로 학습한 모델의 성능을 측정하기 위한 데이터셋
  - **Test 데이터셋 (평가 데이터셋)**
    - 모델의 성능을 최종적으로 측정하기 위한 데이터셋(모의고사 느낌)
    - **Test 데이터셋은 마지막에 모델의 성능을 측정하는 용도로 한번만 사용되어야 한다**
        - 학습과 평가를 반복하다 보면 모델이 검증때 사용한 데이터셋이 과적합 되어 새로운 데이터에 대한 성능이 떨어지기도 함
        - 그래서 데이터셋을 [train_set, validation_set, test_set]으로 나눠 train_set와 validation_set로 모델을 최적화 한 뒤 마지막에 test_set으로 최종평가를 한다

#### Hold Out(데이터가 충분할 때 주로 사용)
  - 데이터셋을 Train set, Validation set, Test set으로 나눈다
  - sklearn.model_selection.train_test_split() 함수 사용
![image](https://user-images.githubusercontent.com/76146752/111754019-db64da80-88da-11eb-86df-d751efe08482.png)
  - dataset을 Train set과 test set으로 먼저 나눈후 Training set을 다시 Training set과 validation set으로 나눈다
  - 
      ``` python
            from sklearn.tree import DecisionTreeClassifier
            from sklearn.metrics import accuracy_score
            from sklearn.datasets import load_iris
            from sklearn.model_selection import train_test_split

            # Dataset loading
            iris = load_iris()
            X,y = iris['data'],iris['target']

            # Train, Test Dataset 분리
            X_train,X_test,y_train,y_test = train_test_split(X,y,
                                                             test_size = 0.2,
                                                             stratify = y,
                                                             random_state = 1)

            # Train, Validation Dataset 분리
            X_train, X_val, y_train,y_val = train_test_split(X_train,y_train,
                                                             test_size = 0.2,
                                                             stratify = y,
                                                             random_state=1)
            # 모델 생성
            tree = DecisionTreeClassifier(max_depth=3, random_state=1) # max_dept: 질문개수(하이퍼 파라미터(hyper parameter))

            # 모델 Train
            tree.fit(X_train, y_train)

            # 예측 및 검증 (validation set)
            pred_train = tree.predict(X_train)
            pred_val = tree.predict(X_val)

            acc_train = accuracy_score(y_train, pred_train)
            acc_val = accuracy_score(y_val, pred_val)

            print('Train accuracy:', acc_train')
            print('Validation accuracy:', acc_val)

            # test dataset으로 마지막 평가(검증)
            pred_test = tree.predict(X_test)
            acc_test = accuracy_score(y_test,pred_test)
            print('최종 검증결과(test):', acc_test)
       ```
       
   - Holdout 방식의 단점
      - train/test 셋이 어떻게 나눠지는지에 따라 결과가 달라짐
        - 데이터가 충분히 많을 때는 변동성이 흡수돼 괜찮으나 수천건 정도로 적을 때는 문제 발생
      - 데이터셋의 양이 적을 수록 학습을 위한 데이터 양이 적어 학습이 제대로 되지 않을 수 있음(데이터 양이 많아야 유의미함)

  #### K-겹 교차검증 (K-Fold Cross Validation)
    
   - 데이터셋을 K개로 나눈 뒤 하나를 검증 세트로 나머지 훈련세트로 하여 모델을 학습/ 평가
   - 이렇게 나눈 데
   - 이터셋이 돌아가면서 한번씩 검증세트가 되도록 k번 반복하여 모델 학습
   - 종류
    - K-Fold
    - Stratified K-Fold
   ![image](https://user-images.githubusercontent.com/76146752/111943422-beb5e600-8b18-11eb-8705-d3c6b5d80ea1.png)

  ##### KFold
   - 지정한 개수(K)만큼 분할한다
   -   
       ``` python
           from sklearn.datasets import load_iris
           from sklearn.model_selection import kFold
           from sklearn.tree import DecisionTreeClassifier
           from sklearn.metrics import accuracy_score

           iris = load_iris()
           X, y = iris['data'],iris['target']

           # 객체를 생성하면서 몇 개의 fold로 나눌지 (K값)을 지정
           kfold = KFold(n_splits =3) # K=3

           # kfold.split(나누려는 Inputdata) : generator 반환
           gen = kfold.split(X)

           next(gen) # 값이 아닌 index가 불러와짐

           next(gen) # 두번째 iteration에서는 2번째가 test 됨 / 이런식으로 k번 반복


           acc_train_list = [] # trainset으로 평가한 정확도를 저장할 리스트
           acc_test_list = [] # testset으로 평가한 정확도를 저장할 리스트

           for train_index, test_index in kfold.split(X,y):
             # 데이터셋 분리
             X_train, y_train = X[traind_index],y[train_index]
             X_test, y_test = X[test_index],y[test_index]

             # 모델 생성
             tree = DecisionTreeCalssifier(max_depth=2)

             # 학습
             tree.fit(X_train,y_train)

             # 검증
             pred_train = tree.predict(X_train)
             pred_test = tree.predict(X_test)

             acc_train = accuracy_score(y_train,pred_train)
             acc_test = accuracy_score(y_test, pred_test)

             # 평가결과 리스트에 넣기
             acc_train_list.append(acc_train)
             acc_test_list.append(acc_test)

            import numpy as np
            print('train 정확도:', np.mean(acc_train_list))
            print('test 정확도:', np.mean(acc_test_list))
        ```

 ##### K-Fold의 문제점
  - 원 데이터셋의 row 순서대로 분할하기 때문에 불균형 문제가 발생할 수 있다(target값이 케이스한쪽으로 몰려있을 수 있음)

#### StratifiedKFold
  - 나뉜 fold들에 label의 비율이 거의 같게 구성되도록 나눈다
  - 
    ``` python
        from sklearn.tree import DecisionTreeCalssifier
        from sklearn.metrics import accuracy_score
        from sklearn.model_selection import StratifiedKFold
        
        s_fold = StratifiedKFold(n_splits=4) # 객체생성시 몇개의 fold로 나눌지 지정(k값)
        s_gen = s_fold.split(X,y) # label별 동일한 분포로 분할해야 하므로 label데이터셋(y)도 같이 준다
        
        acc_train_list = []
        acc_test_list = []
        
        for train_index, test_index in s_gen:
          # train, test set data 분리 생성
          X_train ,y_train = X[train_index],y[train_index]
          X_test, y_test = X[test_index], y[test_index]
          
          # 모델 생성/ 학습
          tree = DecisionTreeClassifier(max_depth = 2)
          tree.fit(X_train,y_train)
          
          # 검증
          pred_train = tree.predict(X_train)
          pred_test = tree.predict(X_test)
          
          acc_train = accuracy_score(y_train, pred_train)
          acc_test = accuracy_score(y_test, pred_test)
          
          # 평가결과 리스트에 추가
          acc_train_list.append(acc_train)
          acc_test_list.append(acc_test)
      ```
 #### cross_val_score()
  - 데이터셋을 k개로 나누고 K번 반복하면서 평가하는 작업을 처리해주는 함수
  - 주요매개변수
    - estimator : 학습할 평가모델객체
    - X : feature
    - y : label
    - scoring: 평가지표
    - cv : 나눌개수(K)
  - 반환값: array - 각 반복마다의 평가 점수
  - 
    ``` python
        from sklearn.model_selection import cross_val_score
        from sklearn.datasets import load_iris
        from sklearn.tree import DecisionTreeCalssifier
        from sklearn.metrics import accuracy_score
        import numpy as np
        
        tree = DecisionTreeClassifier(max_depth=2)
        scores = cross_val_scroe(estimator=tree,
                                 X = X,
                                 y = y,
                                 scoring = 'accuracy',
                                 cv =4)
        print(scores)
        print(np.mean(scores)
    ```


