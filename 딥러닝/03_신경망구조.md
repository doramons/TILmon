# DNN (Deep Neural Network)
## 신경망(Neural Network) 구성요소
### 딥러닝 프로세스
![image](https://user-images.githubusercontent.com/76146752/115322838-dd63d700-a1c1-11eb-833b-f3a88abe6b8b.png)
  - **층(Layer)** : Network를 구성하는 Layer(층)
  - **손실함수(loss function)**: 가중치를 어떻게 업데이트할 지 예측결과와 Ground truth(실제타깃) 사이의 차이를 정의
  - **optimizer** : 가중치를 업데이트 하여 모델의 성능을 최적화

### 유닛/노드/뉴런 (Unit, Node, Neuron)
  - Tensor를 입력받아 tensor를 출력하는 데이터 처리 모듈
  - 입력 값에 Weight(가중치)를 곱하고 bias(편향)을 더한 뒤 활성화 함수를 거쳐 출력한다
  - 하나의 노드 구성
![image](https://user-images.githubusercontent.com/76146752/115323061-451a2200-a1c2-11eb-883d-6b74b1118c6a.png)
      - **Input vector(입력값): 𝕩=(𝑥1,𝑥2,𝑥3)𝑇
      - **Weight(가중치) : 𝕨=(𝑤1,𝑤2,𝑤3)𝑇
      - **Bias(편향) : 𝑏∈ℝ
      - **Activation function(활성함수) : 𝜎(⋅)
      - 𝑧=𝑤1𝑥1+𝑤2𝑥2+𝑤3𝑥3+𝑏 ⇔ 𝑧=𝕨𝑇𝕩+𝑏
      - 𝑎=𝜎(𝑧)
      - 
        ``` python
            from tensorflow.keras import layers
            layers.Dense(units=20) # unit/node를 생성 => 20개
            layers.Dense(units=20, activation='sigmoid') # unit들에 활성함수를 설정 - sigmoid(logistic)함수
        ```
### 레이어/층(Layer)

  - **Input Layer(입력층)** : 입력값들을 받아 Hidden Layer에 전달하는 노드들로 구성된  Layer.
  - **Output Layer(출력층)** : 예측결과를 출력하는 노드들로 구성된 Layer
  - **Hidden Layer(은닉층)**
      - Input Layer와 Output Layer사이에 존재하는 Layer
  - 대부분 Layer들은 가중치를 가짐(dropout, pooling과 같이 가중치가 없는 layer도 있음)
  - **Network(망)**: Layer들의 연결
  - 많이 사용되는 Layer의 예
      - Fully connected layer(Dense layer)
      - convolution layer
      - Recurrent layer
      - Embedding layer

### 모델 (Network)
  
  - Layer를 쌓아 만드는 네트워크
  - 이전 레이어의 출력을 input으로 받아 output을 주는 층을 순서대로 쌓음
  - 적절한 network 구조(architecture)를 찾는 것은 과학보다는 예술의 경지(많은 경험이 필요)
  - 기존의 잘 작동한 구조를 기반으로 구현하는 방식으로 접근

![image](https://user-images.githubusercontent.com/76146752/115366741-892c1780-a200-11eb-8c0a-6df93f4d0af5.png)


### 딥러닝(Deep Learning)
  - 신경망이 많아지는 깊은 딥러닝이라고 한다

![image](https://user-images.githubusercontent.com/76146752/115366863-a234c880-a200-11eb-98c0-2eb5cc9824cf.png)
  
### 손실함수(Loss function, 비용함수)

  - Model을 통해 나온 예측값(prediction) 𝑦̂ (𝑖)와 실제 데이터(output) 𝑦(𝑖)의 차이를 수량화하는 함수
  - 훈련하는 동안 최소화될 값으로 이 값을 바탕으로 파라미터(가중치와 편향)을 업데이트한다
  - 문제의 종류에 따라 다른 Loss 함수를 사용한다

**해결하려는 문제의 종류에 따라 표준적인 Loss function이 존재함**

  - ## Binary classification (이진 분류)
      - 두 개의 클래스를 분류
      - 예) 문장을 입력하여 긍정/부정 구분
      - **binary crossentropy**를 loss function으로 사용
      - 𝐿𝑜𝑠𝑠(𝑦̂ (𝑖),𝑦(𝑖))=−𝑦(𝑖)𝑙𝑜𝑔(𝑦̂ (𝑖))−(1−𝑦(𝑖))𝑙𝑜𝑔(1−𝑦̂ (𝑖))
      - 𝑦(𝑖) : 실제 값(Ground Truth), 𝑦̂ (𝑖): 예측확률
  - ## Multi-class classification (다중 클래스 분류)
      - 두 개 이상의 클래스를 분류
          - 여러개 중 하나
      - 예) 이미지를 0,1,2,....,9로 구분
      - **categorical_crossentropy**를 loss function 으로 사용
      - 𝑦(𝑖) : 실제 값(Ground Truth), 𝑦̂ (𝑖)𝑐: class별 예측확률
   
   - ## Regression(회귀)
      - 연속형 값을 예측
      - 예) 주가 예측
      - **Mean squared error**를 loss function으로 사용
      - 𝐿𝑜𝑠𝑠(𝑦̂ (𝑖),𝑦(𝑖))=1/2(𝑦̂ (𝑖)−𝑦(𝑖))2

  ### 평가지표 (Metrics)
   - 모델의 성능을 평가하는 지표
   - 손실함수(Loss Function)와 차이
      - 손실함수는 모델을 학습할 때 가중치 업데이트를 위한 오차를 구할 때 사용한다
      - 평가지표 함수는 모델의 성능이 확인하는데 사용한다
  
## 활성 함수(Activation Function)

  - 각 유닛이 입력결과를 처리결과를 처리한 후 출력하기 위해 거지는 함수
  - 같은 층(layer)의 모든 유닛들은 같은 활성 함수를 가진다
  - 최종 **출력 레이어의 경우 문제유형에 따른 표준 활성화 함수가 존재한다.**
  - 은닉층 (Hidden Layer)의 경우 **ReLU** 함수를 주로 사용한다.

### 주요 활성함수(Activation Function)
  - ### Sigmoid (logistic function)
![image](https://user-images.githubusercontent.com/76146752/115180474-9e297d80-a110-11eb-8ee5-b895a1260a5c.png)
    
   - 0 < 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝑧) < 1
   - 한계
   - ### Binary classification(이진 분류)를 위한 네트워크의 Output layer(출력층)의 활성함수로 사용된다
      - 위와 같은 한계 때문에 hidden layer(은닉층)의 활성함수로는 잘 사용되지 않는다
      
      > ### 기울기 소실(Gradient Vanishing)
      >   - 최적화 과정에서 gradient가 0과 밑단층(Bottom Layer)의 가중치들이 학습이 안되는 현상
      >   
   - ### Hypterbolic tangent
  ![image](https://user-images.githubusercontent.com/76146752/115180745-51927200-a111-11eb-8a0a-12339877e998.png)
    - −1 < 𝑡𝑎𝑛ℎ(𝑧) < 1
    - Output이 0을 중심으로 분포하므로 sigmoid보다 학습에 효율적이다
    - 여전히 기울기 소실(Graident Vanishing) 문제를 발생시킨다
    - 이진분류 출력층에 쓰곤함(ex. gan 모델)

   - ### ReLU(Tectified Linear Unit)
  ![image](https://user-images.githubusercontent.com/76146752/115180894-a59d5680-a111-11eb-948f-c4f28ce1366b.png)
      - 𝑅𝑒𝐿𝑈(𝑧)=𝑚𝑎𝑥(0,𝑧)
      - 기울기 소실(Gradient Vanishing) 문제를 어느정도 해결
      - 0 이하의 값(z<=0)들에 대해 뉴런이 죽는 단점이 있다(Dying ReLU)

   - ### Leaky ReLU
   ![image](https://user-images.githubusercontent.com/76146752/115181010-e85f2e80-a111-11eb-846c-8b9871b98f22.png)
    - 𝐿𝑒𝑎𝑘𝑦𝑅𝑒𝐿𝑈(𝑧)=𝑚𝑎𝑥(𝛼𝑧,𝑧)
    - 0 < 𝛼 < 1
    - ReLU의 Dying ReLU 현상을 해결하기 위해 나온 함수 - 음수 z를 0으로 반환하지 않고 alpha (0~1 사이 실수)를 곱해 반환한다

   - ### Softmax
        - 𝑆𝑜𝑓𝑡𝑚𝑎𝑥(𝑧𝑗) = 𝑒𝑥𝑝(𝑧𝑗)/∑𝐾𝑘=1𝑒𝑥𝑝(𝑧𝑘)
        -  𝑗=1,2,…,𝐾
      -  **Multi-class classification(다중분류)를 위한 네트워크의 Output Layer(출력층)의 활성함수로 사용된다 **
        - 은닉층의 활성함수로 사용하지 않는다
      -  각 class의 score를 정규화 하여 각 class에 대한 확률 값으로 변환
          - 출력 노드들의 값은 0~1 사이의 실수로 변환되고 그 값의 총 합은 1이된다

![image](https://user-images.githubusercontent.com/76146752/115213617-a8617100-a13c-11eb-84c4-d3249673e764.png)

![image](https://user-images.githubusercontent.com/76146752/115213633-ac8d8e80-a13c-11eb-81e1-a61dff3a17e1.png)

### Optimizer(최적화 방법)
  - Loss function을 기반으로 네트워크가 어떻게 업데이트 될지를 결정하는 알고리즘
     - 경사하강법과 오차 역전파(back propagation) 알고리즘을 이용해 weight를 최적화 한다


#### Gradient Decent(경사하강법)
  - ### 최적화
    - 모델(네트워크)가 출력한 결과와 실제값(Ground Truth)의 차이를 정의하는 함수를 **Loss function(손실함수, 비용함수)** 라고 한다
    - Train 시 Loss function이 출력하는 값을 줄이기 위해 파라미터(weight, bias)를 update 과정을 최적화 (Optimization)이라고 한다
  - Gradient Decent(경사하강법)
    - 최적화를 위해 파라미터들에 대한 loss function의 Gradient값을 구해 Gradient의 반대 방향으로 일정 크기만큼 파라미터들을 업데이트 하는 것을 경사하강법이라고 한다  한

#### 파라미터 업데이트 단위
  - Batch Gradient Decent(배치 경사하강법)
      - Loss를 계산할 때 전체 학습데이터를 사용해 그 평균값을 기반으로 파라미터를 최적화한다
      - 많은 계산량이 필요해서 속도가 느리다. 학습 데이터가 클 경우 메모리가 부족할 수 있다
  - Mini Batch Stochastic Gradient Deccent (미니 배치 확률적 경사하강법)
      - Loss를 계산할 때 전체 데이터를 다 사용하지 않고 지정한 데이터양(batch size)만큼 다 계산해 파라미터를 업데이트한다
      - 계산은 빠른 장점이 있지만 최적값을 찾아가는 방향이 불안정하여 부정확하다 그러나 반복횟루를 늘리면 Batch방식과 유사한 결과로 수렴한다
      > **스텝(Step)** : 한 번 파라미터를 업데이트하는 단위
 
  ![image](https://user-images.githubusercontent.com/76146752/115376438-aaddcc80-a209-11eb-9856-cc2dc73bcd39.png)
  
 ## 오차 역전파(Back Propagation)
  - 딥러닝 학습시 파라미터를 최적화 할 때 추론한 역방향으로 loss를 전달하여 단계적으로 파라미터들을 업데이트한다
      - Loss에서부터 (뒤에서부터) 한계단씩 미분해 gadient 값을 구하고 이를 chain rule(연쇄법칙)에 의해 곱해가면서 파라미터를 최적화한다

  ### 계산 그래프(Computational Graph)
   - 복잡한 계산 과정을 자료구조의 하나인 그래프로 표현한 것
   - 그래프는 노드(Node)와 엣지(Edge)로 구성됨
      - 노드: 연산으로 정의
      - 엣지: 데이터가 흘러가는 방향

  #### 계산 그래프의 예
   - 슈퍼에서 1개 100원인 사과를 2개 샀을 때 지불할 금액은 어떻게 될까? 단 부가세는 10% 부과된다
   ![image](https://user-images.githubusercontent.com/76146752/115377607-c09fc180-a20a-11eb-8595-e3e803ba7bd0.png)
  
  #### 계산 그래프 장점
   - 계산 그래프를 사용한 문제 풀이 절차
      - 계산 그래프를 구성
      - 계산 방향을 결정
          - 왼쪽에서 오른쪽 방향으로 계산 : **순전파(Forward propagation)**
          - 오른쪽 방향에서 왼쪽 방향으로 계산 : **역전파(Back propagation)**
   - 특징/장점
      - **국소적 계산**을 통해 결과를 얻는다
          - 각 노드의 계산은 자신과 관계된 정보(입력 값들)만 가지고 계산한 뒤 그 결과를 다음으로 출력한다
      - 복잡한 계산을 단계적으로 나눠 처리마르로 문제를 단순하게 만들어 계산할 수 있다
          - **딥러닝에서 역전파를 이용해 각 가중치 업데이트를 위한 미분(기울기) 계산을 효율적으로 할 수 있게 된다.**
      - 중간 계산결과를 보관할 수 있다

 ### 합성함수의 미분
  
  - ### 합성함수 : 여러 함수로 구성된 함수
      - 𝑧 = (𝑥+𝑦)2
      - 𝑧=𝑡2
      - 𝑡=𝑥+𝑦
  - ### 연쇄 법칙(Chain Rule)
     - 합성함수의 미분은 합성함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다
![image](https://user-images.githubusercontent.com/76146752/115379350-6b64af80-a20c-11eb-9582-0855275a75d4.png)

#### 연쇄 법칙과 계산 그래프
![image](https://user-images.githubusercontent.com/76146752/115379530-93541300-a20c-11eb-8cd0-102b8213b32b.png)

## 딥러닝 네트워크에서 최적화 예
![image](https://user-images.githubusercontent.com/76146752/115379578-9ea73e80-a20c-11eb-9712-4c46a7195700.png)
![image](https://user-images.githubusercontent.com/76146752/115379596-a2d35c00-a20c-11eb-89ff-69a94878ab9d.png)
 
 - 𝑊11 을 업데이트 하기 위한 미분값은?
 ![image](https://user-images.githubusercontent.com/76146752/115379745-c8606580-a20c-11eb-9e81-60e9576357ad.png)
 ![image](https://user-images.githubusercontent.com/76146752/115379778-cf877380-a20c-11eb-871c-a2afb7fbdb8a.png)
 
 ### SGD를 기반으로 한 주요 옵티마이저
  - 방향성을 개선한 최적화 방법
      - Momentum
      - NAG(Nesterov Accelerated Gradient)
  - 학습률을 개선한 최적화 방법
      - Adagrad
      - RMSProp
  - 방향성 + 학습률 개선 최적화 방법
      - Adam

![image](https://user-images.githubusercontent.com/76146752/115393549-cacabb80-a21c-11eb-89e6-4601503b6f25.png)


