## GlobalAveragePooling (GAP)

- Feature mapì˜ ì±„ë„ë³„ë¡œ í‰ê· ê°’ì„ ì¶”ì¶œ
- 1x1xchannelì˜ Feature map ì„ ìƒì„±
- `model.add(keras.layers.GlobalAveragePooling2D())`
![image](https://user-images.githubusercontent.com/76146752/116251731-e9472e80-a7a9-11eb-9225-7ae1f621a4a4.png)

- Feature Extraction layerì—ì„œ ì¶”ì¶œí•œ Feature mapì„ Classifier layerë¡œ Flattení•´ì„œ ì „ë‹¬í•˜ë©´ ë§ì€ ì—°ê²°ë…¸ë“œì™€ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•˜ê²Œ ëœë‹¤. GAPë¥¼ ì‚¬ìš©í•˜ë©´ ë…¸íŠ¸ì™€ íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆë‹¤.
- Feature mapì˜ ì±„ë„ìˆ˜ê°€ ë§ì„ ê²½ìš° GAPë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì´ë‚˜ ì±„ë„ìˆ˜ê°€ ì ë‹¤ë©´ Flattenì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤
![image](https://user-images.githubusercontent.com/76146752/116252362-77231980-a7aa-11eb-861d-1b477c2215ba.png)

``` python
    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    import gdown
    url = 'https://drive.google.com/uc?id=1nBE3N2cXQGwD8JaD0JZ2LmFD-n3D5hVU'
    fname = 'cats_and_dogs_small.zip'
    gdown.download(url,fname, quiet=False)
    
    !mkdir data
    
    # ì••ì¶œí’€ê¸°
    !unzip -q ./cats_and_dogs_small.zip -d data/cats_and_dogs_small
```

![image](https://user-images.githubusercontent.com/76146752/116253343-5e673380-a7ab-11eb-9091-5c7f785353db.png)

## Transfer learning (ì „ì´í•™ìŠµ)

- í° ë°ì´í„° ì…‹ì„ ì´ìš©í•´ ë¯¸ë¦¬ í•™ìŠµëœ pre-trained Modelì˜ Weightë¥¼ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ í•˜ë ¤ëŠ” ì˜ˆì¸¡ ë¬¸ì œì— í™œìš©
- ### Convolution base(Feature Extraction ë¶€ë¶„)ë§Œ í™œìš©
    - Convolution baseëŠ” ì´ë¯¸ì§€ì— ë‚˜íƒ€ë‚˜ëŠ” ì¼ë°˜ì ì¸ íŠ¹ì„±ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ë¶€ë¶„ì´ë¯€ë¡œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤
    - Classifier ë¶€ë¶„ì€ í•™ìŠµí•˜ë ¤ëŠ” ë°ì´í„°ì…‹ì˜ classë“¤ì— ë§ê²Œ ë³€ê²½í•´ì•¼ í•˜ë¯€ë¡œ ì¬ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤
        - ex) ë™ë¬¼ classë¥¼ êµ¬ë¶„í•˜ëŠ” ëª¨ë¸ì— dog/cat ë¶„ë¥˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° dog/cat êµ¬ë¶„í•˜ëŠ” weightë§Œ ì‚¬ìš©í•˜ê³  ë¶„ë¥˜ê¸°ëŠ” ë”°ë¡œ ì§€ì •í•´ì•¼í•¨
- pretrained convolution layerì˜ í™œìš©
    - Feature extraction
        - í•™ìŠµì‹œ í•™ìŠµë˜ì§€ ì•Šê³  Featureë¥¼ ì¶”ì¶œí•˜ëŠ” ì—­í• ë§Œ í•œë‹¤
    - Fine tuning
        - í•™ìŠµì‹œ Pretrained Convolution layerë„ ê°™ì´ í•™ìŠµí•´ì„œ ë‚´ ë°ì´í„°ì…‹ì— ë§ì¶˜ë‹¤

## Feature extraction

  - ê¸°ì¡´ì˜ í•™ìŠµëœ networkì—ì„œ fully connected layerë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ weightë¥¼ ê³ ì •í•˜ê³  ìƒˆë¡œìš´ ëª©ì ì— ë§ëŠ” fully connected layerë¥¼ ì¶”ê°€í•˜ì—¬ ì¶”ê°€ëœ weightë§Œ í•™ìŠµí•˜ëŠ” ë°©ë²•
  - `tensorflow.keras.applications` moduleì´ ì§€ì›í•˜ëŠ” image classification models
![image](https://user-images.githubusercontent.com/76146752/116254867-ac306b80-a7ac-11eb-8fcb-0016e6d56fa2.png)

> ## ImageNet
>   - ì›¹ìƒì—ì„œ ìˆ˜ì§‘í•œ ì•½ 1500ë§Œì¥ì˜ ë¼ë²¨ë§ëœ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ì•½ 22000ê°œ ì¹´í…Œê³ ë¦¬ë¡œ êµ¬ì„±ëœë‹¤

> ## ILSVRC(ImageNet Large Scale Visual Recognition Challenge)ëŒ€íšŒ
>   - 2010ë…„ë¶€í„° 2017ë…„ê¹Œì§€ ì§„í–‰ëœ ì»´í“¨í„° ë¹„ì „ ê²½ì§„ëŒ€íšŒ
>   - ImageNetì˜ ì´ë¯¸ì§€ì¤‘ **1000ê°œ ì¹´í…Œê³ ë¦¬ ì•½ 120ë§Œ ì¥ì˜ í•™ìŠµìš© ì´ë¯¸ì§€, 5ë§Œì¥ì˜ ê²€ì¦ ì´ë¯¸ì§€, 15ë§Œì¥ì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼** ì´ìš©í•´ ëŒ€íšŒë¥¼ ì§„í–‰í•œë‹¤
>   - **2012ë…„** CNNê¸°ë°˜ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì¸ **Alexnet**ì´ 2ìœ„ì™€ í° ì°¨ì´ë¡œ ìš°ìŠ¹í•˜ë©° ì´í›„ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì´ ëŒ€ì„¸ê°€ ë˜ì—ˆë‹¤. íŠ¹íˆ 2015ë…„ ìš°ìŠ¹í•œ ResNetì€ 0.036ì˜ ì—ëŸ¬ìœ¨ì„ ë³´ì´ë©° ìš°ìŠ¹í–ˆëŠ”ë° ì´ëŠ” ì‚¬ëŒì˜ ì—ëŸ¬ìœ¨ì´ë¼ ì•Œë ¤ì§„ 0.05ë³´ë‹¤ ë†’ì€ ì •í™•ë„ì˜€ë‹¤. 
>   - ILSVRCì—ì„œ ìš°ìŠ¹í•˜ê±°ë‚˜ ì¢‹ì€ ì„±ì ì„ ì˜¬ë¦° ëª¨ë¸ë“¤ì´ ì»´í“¨í„° ë¹„ì „ë¶„ì•¼ ë°œì „ì— í° ì—­í• ì„ í•´ì™”ìœ¼ë©° ì´í›„ ë‹¤ì–‘í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ë°±ë³¸(backbone)ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆë‹¤.

![image](https://user-images.githubusercontent.com/76146752/116256531-3d541200-a7ae-11eb-94e9-a0a22534aaf0.png)

## VGG16 ëª¨ë¸
  
  - ImageNet ILSVRC challenge 2014ì—ì„œ 2ë“±í•œ ëª¨ë¸ë¡œ Simonyan and Zisserman(Oxford Univ.) ì— ì˜í•´ ì œì•ˆ
      - VGGNetì´ ì¤€ìš°ìŠ¹ì„ í•˜ê¸´ í–ˆì§€ë§Œ, êµ¬ì¡°ì˜ ê°„ê²°í•¨ê³¼ ì‚¬ìš©ì˜ í¸ì˜ì„±ìœ¼ë¡œ ì¸í•´ 1ë“±í•œ GoogleLeNetë³´ë‹¤ ë” ê°ê´‘ë°›ì•˜ë‹¤
  - ë‹¨ìˆœí•œ êµ¬ì¡°ë¡œ ì§€ê¸ˆê¹Œì§€ ë§ì´ ì‚¬ìš©
  - ì´ 16ê°œ layerë¡œ êµ¬ì„±ë¨
  - ë„¤íŠ¸ì›Œí¬ ê¹Šì´ê°€ ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ì§€ ì—°êµ¬í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ë„¤íŠ¸ì›Œí¬ë¡œ ë™ì¼í•œ kernel sizeì— convolutionì˜ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬ì„±ë¨
      - 11 layer, 13 layer, 16 layer, 19 layerì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ í…ŒìŠ¤íŠ¸í•¨
      - 19 layerì˜ ì„±ëŠ¥ì´ 16 layerë³´ë‹¤ í¬ê²Œ ë‚˜ì•„ì§€ì§€ ì•ŠìŒ
  - Filterì˜ ìˆ˜ê°€ 64, 128, 256, 512 ë‘ ë°°ì”© ì»¤ì§
  - í•­ìƒ 3x3 filter, stride = 1, same padding, 2x2 MaxPooling ì‚¬ìš©
      - ì´ì „ AlexNetì´ 5x5í•„í„°ë¥¼ ì‚¬ìš©í–ˆëŠ”ë° VGG16ì€  3x3 í•„í„° ë‘ê°œë¥¼ ìŒ“ì•„ ì‚¬ìš©í–ˆë‹¤
          - 3x3í•„í„° ë‘ê°œë¥¼ ìŒ“ëŠ” ê²ƒì´ 5x5 í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ì ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ë©° ì„±ëŠ¥ì´ ë” ì¢‹ì•˜ë‹¤
      - Feature mapì˜ ì‚¬ì´ì¦ˆë¥¼ convolution layerê°€ ì•„ë‹Œ Max Poolingì„ ì‚¬ìš©í•´ ì¤„ì—¬ì¤Œ
  - VGG16ì˜ ë‹¨ì ì€ ë§ˆì§€ë§‰ì— ë¶„ë¥˜ë¥¼ ìœ„í•´ Fully Connected Layer 3ê°œë¥¼ ë¶™ì—¬ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ë„ˆë¬´ ë§ì•„ì¡Œë‹¤. ì•½ 1ì–µ4ì²œë§Œ ê°œì˜ parameter(ê°€ì¤‘ì¹˜) ì¤‘ 1ì–µ2ì²œë§Œê°œì •ë„ê°€ Fully Connected Layerì˜ íŒŒë¼ë¯¸í„°ì„

![image](https://user-images.githubusercontent.com/76146752/116258187-b0aa5380-a7af-11eb-9a35-8a26a741f477.png)

## ResNet (Residual Networks)

  - ì´ì „ ëª¨ë¸ë“¤ê³¼ ë¹„êµí•´ shortcut connection ê¸°ë²•ì„ ì´ìš©í•´ layerìˆ˜ë¥¼ íšê¸°ì ìœ¼ë¡œ ëŠ˜ë¦° CNNëª¨ë¸ë¡œ ILSVRC 2015ë…„ ëŒ€íšŒì—ì„œ ìš°ìŠ¹ì„ ì°¨ì§€í•¨
![image](https://user-images.githubusercontent.com/76146752/116259335-ad639780-a7b0-11eb-9152-80e24351bcfb.png)

  - ë ˆì´ì–´ë¥¼ ê¹Šê²Œ ìŒ“ìœ¼ë©´ ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§€ì§€ ì•Šì„ê¹Œ? 
      - ì‹¤ì œëŠ” Test ì…‹ ë¿ë§Œ ì•„ë‹ˆë¼ Train setì—ì„œë„ ì„±ëŠ¥ì´ ë‚˜ì˜ê²Œ ë‚˜ì˜´
  - Train setì—ì„œë„ ì„±ëŠ¥ì´ ë‚˜ì˜ê²Œ ë‚˜ì˜¨ ê²ƒì€ ìµœì í™” ë¬¸ì œë¡œ ë³´ê³ , ë ˆì´ì–´ë¥¼ ê¹Šê²Œ ìŒ“ìœ¼ë©´ ìµœì í™”í•˜ê¸°ê°€ ì–´ë µë‹¤ê³  ìƒê°í•¨

![image](https://user-images.githubusercontent.com/76146752/116259595-e4d24400-a7b0-11eb-9078-9a0edcebe932.png)

## Idea
![image](https://user-images.githubusercontent.com/76146752/116260028-4e525280-a7b1-11eb-9110-ebfff74e36ef.png)
  
  - ì…ë ¥ê°’ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ëŠ” identity blockì„ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤
  - ê·¸ëŸ¼ Convolution blockì„ identity blockìœ¼ë¡œ ë§Œë“¤ë©´ ìµœì†Œí•œ ì„±ëŠ¥ì€ ë–¨ì–´ì§€ì§€ ì•Šê³  ê¹Šì€ Layerë¥¼ ìŒ“ì„ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ?

## Solution
  - Residual block

![image](https://user-images.githubusercontent.com/76146752/116260500-b4d77080-a7b1-11eb-94e5-f704366704dc.png)
![image](https://user-images.githubusercontent.com/76146752/116260608-cc165e00-a7b1-11eb-8cb7-0b12aa1b26f0.png)

  - ê¸°ì¡´ Layerë“¤ì˜ ëª©í‘œëŠ” ì…ë ¥ê°’ì¸ Xë¥¼ ì¶œë ¥ê°’ì¸ Yë¡œ ìµœì ì˜ ë§¤í•‘í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ H(X)ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤. ê·¸ë˜ì„œ H(X) -Yê°€ ìµœì†Œê°’ì´ ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ë©´ì„œ H(X)ë¥¼ ì°¾ìŒ. ê·¸ëŸ°ë° ë ˆì´ì–´ê°€ ê¹Šì–´ì§€ë©´ì„œ ìµœì í™”ì— ì–´ë ¤ì›€ìœ¼ë¡œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ë¬¸ì œê°€ ë°œìƒ
  - ResNetì€ layerë¥¼ í†µê³¼í•´ì„œ ë‚˜ì˜¨ ê°’ì´ **ì…ë ¥ê°’ê³¼ ë™ì¼í•˜ê²Œ ë§Œë“œëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ëŠ” identity block**ì„ êµ¬ì„±í•œë‹¤
  - Identity blockì€ ì…ë ¥ê°’ Xë¥¼ ë ˆì´ì–´ë¥¼ í†µê³¼ì‹œì¼œì„œ ë‚˜ì˜¨ Yì— ì…ë ¥ê°’ Xë¥¼ ë”í•´ì„œ í•©ì¹˜ë„ë¡ êµ¬ì„±í•œë‹¤

      - ğ»(ğ‘¥)=ğ¹(ğ‘¥)+ğ‘¥
      - ğ‘¥:ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡,ğ»(ğ‘¥):ğ‘œğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡,ğ¹(ğ‘¥):ğ‘™ğ‘ğ‘¦ğ‘’ğ‘Ÿí†µê³¼ê°’
  - ëª©í‘œ H(x)(ë ˆì´ì–´ í†µê³¼í•œ ê°’)ì´ inputì¸ xì™€ ë™ì¼í•œ ê²ƒì´ë¯€ë¡œ F(x)ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ í•™ìŠµì„ í•œë‹¤
  - F(x)ëŠ” **ì”ì°¨(Residual)** ê°€ ëœë‹¤. ê·¸ë¦¬ê³  ì”ì°¨ì¸ F(x)ê°€ 0ì´ ë˜ë„ë¡ í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ë¯€ë¡œ Residual Learningì´ë¼ê³  í•œë‹¤
  - ì…ë ¥ì¸ xë¥¼ ì§ì ‘ ì „ë‹¬í•˜ëŠ” ê²ƒì„ **shortcut connection** ë˜ëŠ” **identity mapping** ë˜ëŠ” **skip connection**ì´ë¼ê³  í•œë‹¤
      - ì´ shortcutì€ íŒŒë¼ë¯¸í„°ì—†ì´ ë‹¨ìˆœíˆ ê°’ì„ ë”í•˜ëŠ” êµ¬ì¡°ì´ë¯€ë¡œ ì—°ì‚°ëŸ‰ì— í¬ê²Œ ì˜í–¥ì´ ì—†ë‹¤
  - ê·¸ë¦¬ê³  Residualì„ ì°¾ëŠ” ë ˆì´ì–´ë¥¼ **Residual Block, Identity Block**ì´ë¼ê³  í•œë‹¤

## ì„±ëŠ¥í–¥ìƒ
  - H(x) = F(x) + xì„ xì— ëŒ€í•´ ë¯¸ë¶„í•˜ë©´ ìµœì†Œí•œ 1ì´ë¯€ë¡œ Gradient Vanishing ë¬¸ì œë¥¼ ê·¹ë³µí•œë‹¤
  - ì”ì°¨í•™ìŠµì´ë¼ê³  í•˜ì§€ë§Œ Residual blockì€ Convolution Layerì™€ Activation Layerë¡œ êµ¬ì„±ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ì´ Layerë¥¼ í†µê³¼í•œ Inputìœ¼ë¡œë¶€í„° Feature mapì„ ì¶”ì¶œí•˜ëŠ” ê³¼ì •ì€ ì§„í–‰ë˜ë©° ë ˆì´ì–´ê°€ ê¹Šìœ¼ë¯€ë¡œ ë‹¤ì–‘í•œ ë”ìš± í’ë¶€í•œ íŠ¹ì„±ë“¤ì„ ì¶”ì¶œí•˜ê²Œ ë˜ì–´ ì„±ëŠ¥ì´ í–¥ìƒëœë‹¤.


## ResNet êµ¬ì¡°
  - Residual blockë“¤ì„ ìŒ“ëŠ” êµ¬ì¡°
  - ëª¨ë“  Identity blockì€ ë‘ê°œì˜ 3x3 convv layerë¡œ êµ¬ì„±ë¨
  - ì¼ì • ë ˆì´ì–´ ìˆ˜ë³„ë¡œ filterì˜ ê°œìˆ˜ë¥¼ ë‘ë°°ë¡œ ì¦ê°€ì‹œí‚¤ë©° strideë¥¼ 2ë¡œ í•˜ì—¬ downsampling í•¨ (Pooling LayerëŠ” Identity blockì˜ ì‹œì‘ê³¼ ë§ˆì§€ë§‰ì—ë§Œ ì ìš©)

![image](https://user-images.githubusercontent.com/76146752/116265136-d6d2f200-a7b5-11eb-985b-8c18e8024595.png)
![image](https://user-images.githubusercontent.com/76146752/116265259-ed794900-a7b5-11eb-9720-88314fa196f2.png)

## Pretrained Model ì‚¬ìš©

 - tensorflow.(eras.applications íŒ¨í‚¤ì§€ë¥¼ í†µí•´ ì œê³µ
 - ëª¨ë¸ì´ë¦„ì´ í´ë˜ìŠ¤ ì´ë¦„
    - VGG16, ResNet153 ë“±ë“±
 - ìƒì„±ì ë§¤ê°œë³€ìˆ˜
    - `weights`: ëª¨í˜•ì˜ í•™ìŠµëœ weight. ê¸°ë³¸ê°’ - 'imagenet'
    - `include_top`: fully connected layerë¥¼ í¬í•¨í• ì§€ ì—¬ë¶€. True í¬í•¨ì‹œí‚´, False: í¬í•¨ ì•ˆì‹œí‚´
    - `input_shape`: ì‚¬ìš©ìê°€ ì…ë ¥í•  ì´ë¯¸ì§€ì˜ í¬ê¸° shape. 3D í…ì„œë¡œ ì§€ì • (ë†’ì´, ë„ˆë¹„, ì±„ë„). ê¸°ë³¸ê°’ (224,224,3)

``` python
    from tensorflow.keras.applications import VGG16, ResNet50V2
    
    conv_base_VGG = VGG16(weights='imagenet', # Imagenet ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ê°€ì¤‘ì¹˜
                          include_top = False, # classificationëŠ” ê°€ì ¸ì˜¤ì§€ ì•ŠìŒ
                          input_shape = (150,150,3))
                          
    conv_base_ResNet = ResNet50V2(weights = 'imagenet',
                                  include_top = False,
                                  input_shape = (150,150,3))
```

## Feature extractionì˜ ë‘ê°€ì§€ ë°©ë²•

  1. ë¹ ë¥¸ ì¶”ì¶œë°©ì‹
      - ì˜ˆì¸¡í•˜ë ¤ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìœ„ì˜ `conv_base`ì— ì…ë ¥í•˜ì—¬ ë‚˜ì˜¨ ì¶œë ¥ê°’ì„ numpy ë°°ì—´ë¡œ ì €ì¥í•˜ê³  ì´ë¥¼ ë¶„ë¥˜ ëª¨ë¸ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš© convolution operationì„ í•˜ì§€ ì•Šì•„ë„ ë˜ê¸° ë•Œë¬¸ì— ë¹ ë¥´ê²Œ í•™ìŠµ. í•˜ì§€ë§Œ data augmentation ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ
  2. ë°›ì•„ì˜¨ íŠ¹ì„± Layerë¥¼ ì´ìš©í•´ ìƒˆë¡œìš´ ëª¨ë¸ êµ¬í˜„í•˜ëŠ” ë°©ì‹
      - ìœ„ì˜ `conv_base` ì´í›„ì— ìƒˆë¡œìš´ layerë¥¼ ìŒ“ì•„ í™•ì¥í•œ ë’¤ ì „ì²´ ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµ. 
      - ëª¨ë“  ë°ì´í„°ê°€ convolution layerë“¤ì„ í†µê³¼í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— í•™ìŠµì´ ëŠë¦¼
      - ë‹¨ conv_baseì˜ ê°€ì¤‘ì¹˜ëŠ” ì—…ë°ì´íŠ¸ ë˜ì§€ ì•Šë„ë¡ í•œë‹¤
      - data augmentation ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ

## ë¹ ë¥¸ íŠ¹ì„± ì¶”ì¶œ ë°©ì‹
  
## Pretrained Networkë¥¼ ì´ìš©í•´ ìƒˆë¡œìš´ ëª¨ë¸ êµ¬í˜„í•˜ëŠ” ë°©ì‹

  - Conv_baseì˜ feature extractionoë¶€ë¶„ì— fully connected layerë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨í˜• ìƒì„±
  - Conv_baseì—ì„œ ê°€ì ¸ì˜¨ ë¶€ë¶„ì€ í•™ìŠµì„ í•˜ì§€ ì•Šê³  weightë¥¼ ê³ ì •
      - **Layer.trainable = Fasle**

``` python
    LEARNING_RATE = 0.001
    N_EPOCHS = 20
    N_BATCHS = 100
    IMAGE_SIZE =150
    
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    
    def create_model():
      conv_base = VGG16(weights = 'imagenet', include_top=False, input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))
      
      conv_base.trainable = False # í•™ìŠµì‹œ weight ìµœì í™”ë¥¼ í•˜ì§€ ì•Šë„ë¡ ì„¤ì •
      # VGG16 ëª¨ë¸ì˜ weightë“¤ì€ ì´ë¯¸ ìµœì í™” ë˜ì–´ìˆê¸° ë–„ë¬¸ì— ì—­ì „íŒŒ í•˜ì—¬ ì—…ë°ì´íŠ¸ ë  í•„ìš”ì—†ìŒ
      
      model = keras.Sequential()
      model.add(conv_base)
      
      model.add(layers.GlobalAveragePooling2D())
      model.add(layers.Dense(256,activation='relu'))
      
      # ì¶œë ¥
      model.add(layers.Dense(1, activation='sigmoid'))
      
      return model
      
     model = create_model()
     model.compile(optimizer= keras.optimizers.Adam(learning_rate = LEARNING_RATE, loass = 'binary_crossentropy', metrics=['accuracy'])
     
     train_iterator, validation_iterator, test_iterator = get_generators()
     
     history = model.fit(train_iterator,
                         epochs = N_EPOCHS
                         steps_per_epoch = len(train_iterator),
                         validation_data = validation_iterator,
                         validation_steps = len(validation_iterator))
                         
 ```
      
      
      
      
      
      
      
      
      
